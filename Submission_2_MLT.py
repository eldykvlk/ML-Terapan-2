# -*- coding: utf-8 -*-
"""Submission 2 MLT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S8uDWTWmV-Hn9KQHzZ4cWF_I-wGGcnip

# Perkenalan Dataset

Proyek ini menggunakan Amazon Sales 2025 Dataset yang diambil dari [Kaggle](https://www.kaggle.com/datasets/zahidmughal2343/amazon-sales-2025). Dataset ini berisi 250 baris data transaksi penjualan di Amazon sepanjang tahun 2025. Meskipun jumlah data kurang dari 500 sampel, dataset ini tetap relevan untuk eksplorasi dan penerapan teknik analisis data atau machine learning berskala kecil. Data mencakup informasi produk, pelanggan, metode pembayaran, hingga status pemesanan.

-- Kolom pada dataset:

- Order ID: ID unik untuk setiap pesanan

- Date: Tanggal transaksi

- Product: Nama produk yang dibeli

- Category: Kategori produk (misalnya Electronics, Clothing, Home Appliances)

- Price: Harga satuan produk

- Quantity: Jumlah produk yang dibeli

- Total Sales: Total pendapatan dari pesanan (Price √ó Quantity)

- Customer Name: Nama pelanggan

- Customer Location: Kota tempat tinggal pelanggan

- Payment Method: Metode pembayaran (Credit Card, Debit Card, PayPal, dll.)

- Status: Status pesanan (Completed, Pending, atau Cancelled)

Proyek ini akan didokumentasikan secara lengkap melalui text cell pada notebook dan bertujuan untuk menganalisis tren penjualan serta memecahkan permasalahan bisnis menggunakan pendekatan eksplorasi data dan visualisasi interaktif.

Oleh: Eldy Effendi untuk Submission 2 Machine Learning Terapan Dicoding

# Task

Membuat sistem rekomendasi dengan Content-Based Filtering

# Rumusan Masalah

1. Bagaimana cara merekomendasikan produk yang sering dibeli bersamaan dengan suatu produk tertentu berdasarkan histori transaksi pelanggan?

2. Seberapa relevan hasil rekomendasi produk tersebut dibandingkan dengan produk-produk relevan yang sebenarnya diharapkan pengguna?

# 1. Data Loading
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re
import pickle

# Load dataset
df = pd.read_csv("/content/amazon_sales_data 2025.csv")
df.head()

"""Pada tahap ini, data penjualan Amazon dibaca dari file CSV ke dalam sebuah DataFrame menggunakan pandas. Library pendukung seperti numpy, matplotlib, seaborn, dan beberapa dari scikit-learn juga diimpor untuk keperluan analisis dan pembuatan model.

# 2. Data Exploration
"""

relevant_features = ['Product', 'Category', 'Price', 'Customer Name', 'Customer Location']
print("Relevant Features:", relevant_features)

# Missing Value Analysis
missing_values = df.isnull().sum()
missing_percentage = (missing_values / len(df)) * 100
missing_info = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})
print("\nMissing Value Analysis:\n", missing_info)

# Distribution Analysis (Numerical Features)
if 'Price' in df.columns and 'Quantity' in df.columns:
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    sns.histplot(df['Price'], kde=True)
    plt.title('Distribution of Price')
    plt.subplot(1, 2, 2)
    sns.histplot(df['Quantity'], kde=True)
    plt.title('Distribution of Quantity')
    plt.tight_layout()
    plt.show()

# Distribution Analysis (Categorical Features)
if 'Category' in df.columns and 'Customer Location' in df.columns:
    plt.figure(figsize=(12, 6))
    plt.subplot(1, 2, 1)
    df['Category'].value_counts().plot(kind='bar')
    plt.title('Distribution of Product Categories')
    plt.xticks(rotation=45, ha='right')

    plt.subplot(1, 2, 2)
    df['Customer Location'].value_counts().plot(kind='bar')
    plt.title('Distribution of Customer Locations')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()

# Correlation Analysis
numerical_features = ['Price', 'Quantity', 'Total Sales']
available_numerics = [col for col in numerical_features if col in df.columns]
if len(available_numerics) >= 2:
    correlation_matrix = df[available_numerics].corr()
    plt.figure(figsize=(8, 6))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
    plt.title('Correlation Matrix of Numerical Features')
    plt.show()

df.describe()

print(df.dtypes)

"""Tahap ini bertujuan untuk memahami struktur dan isi data:

- Identifikasi fitur penting seperti produk, kategori, harga, nama pelanggan, dan lokasi pelanggan.

- Analisis data hilang dilakukan untuk mengetahui berapa banyak nilai kosong pada setiap kolom.

- Distribusi data numerik dan kategorikal divisualisasikan menggunakan histogram dan bar chart.

- Analisis korelasi antara fitur numerik dilakukan untuk mengetahui hubungan antara harga, kuantitas, dan total penjualan.

- Menampilkan data numerik menggunakan fungsi describe() untuk mengetahui hitungan seperti Mean dan lain-lain.

- Menampilkan tipe data.

Output:

- Relevant Features: Menampilkan daftar fitur yang relevan untuk analisis.

- Missing Value Analysis: Menunjukkan bahwa tidak ada nilai yang hilang dalam dataset.

-- Distribution Analysis (Numerical Features):

- Histogram Price: Distribusi harga produk menunjukkan bahwa sebagian besar produk memiliki harga di bawah 200.

- Histogram Quantity: Distribusi kuantitas pembelian menunjukkan bahwa sebagian besar pembelian dilakukan dalam jumlah 1 hingga 5.

-- Distribution Analysis (Categorical Features):

- Bar Chart Category: Distribusi kategori produk menunjukkan bahwa kategori "Electronics" dan "Footwear" mendominasi.

- Bar Chart Customer Location: Distribusi lokasi pelanggan menunjukkan bahwa lokasi tertentu seperti "New York" dan "San Francisco" lebih sering muncul.

- Correlation Analysis: Heatmap korelasi antara fitur numerik (Price, Quantity, Total Sales) menunjukkan bahwa Total Sales memiliki korelasi positif yang kuat dengan Quantity dan Price.

- Data mencakup 250 transaksi, dengan harga rata-rata produk 343.58 (satuan mata uang tidak disebutkan), kuantitas rata-rata 2.86, dan rata-rata total penjualan 975.38.

- Harga produk bervariasi luas (standar deviasi 380.64), mulai dari 15 hingga 1200, sedangkan kuantitas berkisar antara 1 dan 5.

- Total penjualan juga memiliki variasi yang besar (standar deviasi 1252.11), dengan nilai tengah 400 dan nilai maksimum 6000, menunjukkan adanya beberapa transaksi yang jauh lebih besar dari yang lain.

- Kolom 'Order ID', 'Product', 'Category', 'Customer Name', 'Customer Location', 'Payment Method', dan 'Status' bertipe object (string), 'Price', 'Quantity', dan 'Total Sales' bertipe integer, dan kolom 'Date' saat ini bertipe object namun perlu diubah ke tipe datetime.

# 3. Data Cleaning
"""

# Convert 'Date' column to datetime objects
if 'Date' in df.columns:
    try:
        df['Date'] = pd.to_datetime(df['Date'], format='%d-%m-%y', errors='coerce')
    except ValueError:
        print("Error: Invalid date format in 'Date' column.")

# Clean categorical columns
categorical_cols = ['Order ID', 'Product', 'Category', 'Customer Name', 'Customer Location', 'Payment Method', 'Status']
for col in categorical_cols:
    if col in df.columns:
        df[col] = df[col].astype(str).str.strip().str.lower()

# Remove duplicate rows
num_duplicates = df.duplicated().sum()
print("Jumlah duplikasi ditemukan:", num_duplicates)
df = df.drop_duplicates()
print("Jumlah data setelah menghapus duplikasi:", df.shape[0])

# Cek Outlier
if 'Price' in df.columns:
    plt.figure(figsize=(6, 4))
    sns.boxplot(x=df['Price'])
    plt.title("Boxplot Harga Produk (Outlier Detection)")
    plt.tight_layout()
    plt.show()

    Q1 = df['Price'].quantile(0.25)
    Q3 = df['Price'].quantile(0.75)
    IQR = Q3 - Q1
    outliers = df[(df['Price'] < Q1 - 1.5 * IQR) | (df['Price'] > Q3 + 1.5 * IQR)]

"""Tahapan ini membersihkan data agar siap digunakan:

- Konversi kolom tanggal ke format datetime.

- Normalisasi data kategorikal, seperti nama produk dan lokasi pelanggan, diubah menjadi huruf kecil dan dihapus spasi ekstra.

- Penghapusan duplikat baris agar tidak terjadi bias dalam analisis.

- Deteksi dan analisis outlier dilakukan terhadap harga untuk memahami distribusi yang tidak normal.

- Jumlah duplikasi ditemukan: 0: Baris ini mengindikasikan bahwa tidak ada baris duplikat yang terdeteksi dalam DataFrame df sebelum penghapusan. Ini berarti setiap baris dalam dataset adalah unik berdasarkan seluruh kolomnya.

- Jumlah data setelah menghapus duplikasi: 250: Setelah proses pengecekan dan penghapusan duplikasi (meskipun tidak ada yang ditemukan), jumlah total baris dalam DataFrame df adalah 250. Ini adalah ukuran dataset yang akan digunakan untuk analisis selanjutnya.

- Boxplot ini digunakan untuk mendeteksi nilai-nilai ekstrem (outlier) dalam kolom Price.

- Sebagian besar harga produk berada dalam rentang interkuartil (Q1 ke Q3), yaitu antara sekitar 50 hingga 600.

- Terlihat bahwa ada harga-harga yang jauh lebih tinggi dari rentang normal (hingga 1200), yang diklasifikasikan sebagai outlier‚Äîjumlahnya sebanyak 30 data. Deteksi ini penting agar analisis dan model tidak bias karena nilai ekstrem.

# 4. Feature Engineering
"""

# Cleaning Text
def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'[^a-zA-Z0-9 ]', '', text)
    return text

if 'Product' in df.columns and 'Category' in df.columns:
    df['Product_clean'] = df['Product'].apply(clean_text)
    df['Category_clean'] = df['Category'].apply(clean_text)
    df['description'] = df['Product_clean'] + " " + df['Category_clean']

"""Di tahap ini, fitur-fitur baru dibentuk dari data yang ada:

- Pembersihan teks produk dan kategori agar siap diolah oleh model berbasis teks.

- Penggabungan fitur produk dan kategori menjadi deskripsi gabungan untuk masing-masing item, yang akan digunakan untuk analisis berbasis teks.

# 5. Model Training
"""

# TF-IDF dan cosine similarity
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

vectorizer = TfidfVectorizer(stop_words='english')
tfidf_matrix = vectorizer.fit_transform(df['Product'])
cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)

def get_top_n_similar_products(product_name, top_n=5):
    product_name = product_name.lower().strip()
    matching_products = df[df['Product'].str.lower() == product_name]
    if matching_products.empty:
        return "‚ùå Produk tidak ditemukan dalam dataset."

    idx = matching_products.index[0]
    sim_scores = list(enumerate(cosine_sim[idx]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    top_indices = [i for i, _ in sim_scores[1:top_n+1]]

    return df.iloc[top_indices][['Product', 'Status']]

"""TF-IDF Vectorization digunakan untuk mengubah teks deskripsi menjadi vektor numerik.

Cosine Similarity dihitung antar produk berdasarkan vektor deskripsi untuk mengukur seberapa mirip satu produk dengan produk lain.

# 6. Model Evaluation
"""

from sklearn.metrics import ndcg_score
import numpy as np
import pandas as pd

# Fungsi untuk memberikan rekomendasi produk berdasarkan kesamaan deskripsi produk
def recommend_bundled_products(product_name, top_n=5):
    # Normalisasi nama produk
    product_name = product_name.lower().strip()

    # Cari pelanggan yang pernah beli produk ini
    buyers = df[df['Product'].str.lower() == product_name]['Customer Name'].unique()

    # Ambil semua produk yang dibeli oleh pelanggan tersebut, kecuali produk input
    bundled_df = df[df['Customer Name'].isin(buyers) & (df['Product'].str.lower() != product_name)]

    # Hitung frekuensi produk yang dibeli bersama produk input
    bundled_counts = (
        bundled_df['Product']
        .value_counts()
        .head(top_n)
    )

    if bundled_counts.empty:
        return "Tidak ada produk lain yang biasa dibeli bersama produk ini."

    # Mengubah hasil frekuensi menjadi dataframe
    result_df = bundled_counts.reset_index().rename(columns={'index': 'Product', 'Product': 'Frequency'})

    return result_df

# Fungsi untuk menghitung NDCG@5
def evaluate_ndcg(recommended_products, true_relevant_products, top_n=5):
    """
    Evaluasi NDCG@5
    recommended_products: List produk yang direkomendasikan (berdasarkan peringkat)
    true_relevant_products: List produk relevan yang seharusnya muncul (berdasarkan status)
    """
    # Konversi rekomendasi dan produk relevan ke dalam format yang sesuai untuk NDCG
    y_true = np.zeros((1, len(recommended_products)))
    y_score = np.zeros((1, len(recommended_products)))

    # Menandai produk relevan (dalam hal ini, berdasarkan true_relevant_products)
    for idx, product in enumerate(recommended_products):
        if product in true_relevant_products:
            y_true[0, idx] = 1  # Jika produk relevan, beri label 1

    # Menghitung NDCG@5
    score = ndcg_score(y_true, y_score, k=top_n)
    return score

# Contoh penggunaan
top_recommendations_df = recommend_bundled_products("headphones", top_n=5)
top_recommendations = top_recommendations_df['Frequency'].tolist()  # Ambil produk dari kolom 'Product'

# Tampilkan rekomendasi produk dalam format tabel Markdown
print("### üîç Top 5 Rekomendasi Produk Mirip untuk: `Headphones`")
print("| Produk     |   Frekuensi |")
print("|:-----------|------------:|")
for index, row in top_recommendations_df.iterrows():
    print(f"| {row['Frequency']} | {row['count']} |")

# Contoh produk relevan berdasarkan status 'Pending' atau lainnya
true_relevant_products = ['smartphone', 'book', 'laptop']  # Produk relevan yang diinginkan (misalnya produk yang dibeli bersama dengan 'headphones')

# Evaluasi NDCG@5
ndcg_at_5 = evaluate_ndcg(top_recommendations, true_relevant_products)
print(f"\nüìä **NDCG@5** berdasarkan status 'Pending': {ndcg_at_5:.4f}")

"""Fungsi recommend_bundled_products:

1. Mengambil produk yang diminta (misalnya "headphones").

 - Mencari pelanggan yang membeli produk tersebut.

 - Mengambil produk lain yang sering dibeli bersama oleh pelanggan tersebut, kecuali produk yang diminta.

 - Menghitung frekuensi produk yang dibeli bersama dan menampilkan 5 produk teratas berdasarkan frekuensi.

2. Membuat Tabel Rekomendasi Produk:

 - Tabel ini menampilkan 5 produk teratas yang sering dibeli bersama dengan produk "headphones" beserta jumlah frekuensinya.

3. Fungsi evaluate_ndcg:

 - Menghitung skor NDCG@5 untuk mengevaluasi seberapa baik urutan rekomendasi produk dibandingkan dengan produk yang relevan.

 - Produk relevan didefinisikan oleh true_relevant_products (misalnya, produk yang dibeli bersama "headphones", seperti smartphone, book, dan laptop).

4. Proses NDCG:

 - NDCG (Normalized Discounted Cumulative Gain) mengukur relevansi produk yang direkomendasikan dengan cara memberi bobot lebih pada produk relevan yang lebih tinggi posisinya dalam rekomendasi.

 - Skor NDCG@5 dihitung berdasarkan urutan produk yang direkomendasikan dan relevansi produk tersebut dengan produk yang diinginkan.

5. Hasil Output:

 - Tabel yang menunjukkan produk-produk yang direkomendasikan beserta frekuensinya.

 - Skor NDCG@5 yang menunjukkan seberapa baik urutan rekomendasi berdasarkan relevansi produk yang dianggap relevan.

 - Dalam contoh ini, skor NDCG@5 adalah 0.8302, yang menunjukkan bahwa urutan rekomendasi yang dihasilkan cukup baik dalam mengurutkan produk relevan.

# 7. Export Model dan Dataset
"""

with open("cosine_similarity.pkl", "wb") as f:
    pickle.dump(cosine_sim, f)

with open("tfidf_vectorizer.pkl", "wb") as f:
    pickle.dump(vectorizer, f)

output_df = df[['Product', 'Category', 'description']]
output_df.to_csv("processed_amazon_products.csv", index=False)

print("Model dan data berhasil diekspor.")

"""- Model cosine similarity dan TF-IDF vectorizer disimpan dalam file .pkl menggunakan pickle untuk digunakan kembali tanpa perlu pelatihan ulang.

- Dataset hasil praproses (produk, kategori, dan deskripsi gabungan) diekspor ke file CSV untuk dokumentasi atau digunakan dalam aplikasi lain.

# 8. Summary(Jawaban Masalah)

1. Untuk menjawab rumusan pertama, sistem rekomendasi dibangun dengan pendekatan berbasis frekuensi pembelian bersama oleh pelanggan yang sama. Dengan menggunakan nama produk sebagai input, sistem mencari pelanggan yang pernah membeli produk tersebut, lalu mengidentifikasi produk lain yang mereka beli, menghitung frekuensinya, dan menghasilkan daftar rekomendasi produk terbanyak.

2. Untuk menjawab rumusan kedua, relevansi hasil rekomendasi dievaluasi menggunakan metrik NDCG@5 (Normalized Discounted Cumulative Gain) yang mengukur seberapa baik sistem mengurutkan produk relevan di posisi teratas daftar rekomendasi. Berdasarkan hasil uji pada produk Headphones, sistem merekomendasikan produk seperti smartphone, smartwatch, running shoes, book, dan laptop, yang sesuai dengan produk-produk relevan aktual (smartphone, book, laptop).
"""